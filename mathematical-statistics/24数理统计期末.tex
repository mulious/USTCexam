\documentclass[UTF8]{ctexart}
\usepackage{graphicx,amsfonts,amsmath,mathrsfs,amssymb,amsthm,url,color}
\usepackage{fancyhdr,indentfirst,bm,enumerate,natbib,float,tikz}
\usepackage{caption,subcaption,calligra}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{bm}
\usepackage{bbding} 

\title{数理统计24期末}
\author{}
\date{}

\textheight 23cm
\textwidth 16.5cm
\topmargin -1.2cm
\oddsidemargin 0cm
\evensidemargin 0cm

\begin{document}
\maketitle
\noindent 一．（20 分）单项选择填空题（每题 2 分）\\
1．设 $X_1, \ldots, X_n$ 为来自均匀分布 $\mathrm{U}(-\theta, \theta)$ 的一组样本，$\theta$ 为未知参数，则下述量为统计量的是\underline{\hspace{2cm}}\\
（A） $\overline{X}-\theta$\\
（B） $\max _{1 \leq i \leq n}\left(X_i-\theta\right)-\min _{1 \leq i \leq n}\left(X_i-\theta\right)$\\
（C） $\max _{1 \leq i \leq n}\left(X_i-\theta\right)$\\
（D） $\min _{1 \leq i \leq n}\left(X_i-\theta\right)$\\
答案：B\\
统计量要与未知参数无关\\
2．设 $\hat{\theta}_n$ 为末知参数 $\theta$ 的一个估计量，如果 $\lim _{n \rightarrow \infty} \mathbb{E}\left[ \hat{\theta}_n-\theta\right] =0$ ，则 $\hat{\theta}_n$ 为 $\theta$ 的\underline{\hspace{2cm}}\\
（A）无偏估计\\
（B）有效估计\\
（C）相合估计\\
（D）渐近正态估计\\
答案：C\\
3．假设样本 $X$ 的密度为 $f_\theta(x)$ ，其中 $\theta$ 为参数，则下列表述不正确的是\underline{\hspace{2cm}}\\
（A）固定 $x$ 时 $f_\theta(x)$ 为似然函数\\
（B）固定 $\theta$ 时 $f_\theta(x)$ 为似然函数\\
（C）固定 $\theta$ 时 $f_\theta(x)$ 为密度函数\\
（D）$f_\theta(x)$ 衡量了不同 $\theta$ 下观测到值 $x$ 的可能性大小\\
答案：B\\
4．一个参数 $\theta$ 的 $95 \%$ 区间估计为 $[0.1,0.3]$ ，则下列表述正确的是\underline{\hspace{2cm}}\\
（A）若该区间为置信区间，则表明 $\theta$ 位于该区间的概率是 0.95\\
（B）该区间的边际误为 0.2\\
（C）对假设 $H_0: \theta=0.2 \leftrightarrow H_1: \theta \neq 0.2$ ，会在 0.05 水平下拒绝原假设\\
（D）若该区间为贝叶斯可信区间，则表明 $\theta$ 位于该区间的概率是 0.95\\
答案：D\\
5．下列表述错误的是\underline{\hspace{2cm}}\\
（A）矩估计量一般不唯一\\
（B）无偏估计总是优于有偏估计\\
（C）相合性是一个估计量的基本性质\\
（D）最大似然估计可以不存在\\
答案：B\\
6．若 $\delta(X)$ 是一个损失下的 Bayes 法则，则下列表述正确的是\underline{\hspace{2cm}}\\
（A）$\delta(X)$ 的贝叶斯风险不超过 Minimax 风险\\
（B）$\delta(X)$ 不可能是一个 Minimax 法则\\
（C）$\delta(X)$ 是可容许的\\
（D）$\delta(X)$ 的风险为常数\\
答案：A\\
7．下述对一个显著性检验方法的描述错误的是\underline{\hspace{2cm}}\\
（A）原假设与对立假设地位不均等，原假设被保护起来\\
（B）$p$ 值越显著表明原假设成立的依据越强烈\\
（C）在一个检验结果是不能拒绝零假设时，检验只可能会犯第二类错误\\
（D）双边假设的接受域等价于参数的置信区间\\
答案：B\\
8．设 $X_1, \ldots, X_n$ 为来自正态总体 $N(\mu, 1)$ 的简单样本，考虑假设检验问题 $H_0: \mu=0 \leftrightarrow H_1$ ： $\mu=0.5$ 。如果要求检验的第一类和第二类错误均不超过 $\alpha(0<\alpha<1)$ ，则样本量 $n$ 应满足$\underline{n \geq\left\lceil 16 u_\alpha^2\right\rceil}$ （结果用分位数表示）．\\
解：两点假设的拒绝域形如 $R=\{\boldsymbol{X}: \overline{X}>c\}$ ．按要求
$$
\begin{aligned}
	& \alpha \geq \mathrm{P}\left(\boldsymbol{X} \in R \mid H_0\right)=\mathrm{P}_{\mu=0}(\overline{X}>c)=1-\Phi(\sqrt{n} c), \\
	& \alpha \geq \mathrm{P}\left(\boldsymbol{X} \notin R \mid H_1\right)=\mathrm{P}_{\mu=0.5}(\overline{X} \leq c)=\Phi(\sqrt{n}(c-0.5)) .
\end{aligned}
$$
于是我们有
$$
\left\{\begin{array}{l}
	\sqrt{n} c \geq u_\alpha, \\
	\sqrt{n}(c-0.5) \leq-u_\alpha, \quad \Longrightarrow \quad 0.5 \sqrt{n} \geq 2 u_\alpha, \quad \Longrightarrow \quad n \geq\left\lceil 16 u_\alpha^2\right\rceil .
\end{array}\right.
$$
9．设某种产品的质量等级可以划分为＂优＂、＂合格＂和＂不合格＂，为了判断生产此产品的三家工厂的产品是否有差异，使用拟合优度检验方法时的原假设为 $\underline{\text{三家工厂生产的产品质量无差异}} $，渐近卡方分布的自由度为 $\underline{4}$．\\
10．设 $X_1, \ldots, X_n$ 为来自均匀分布 $\mathrm{U}(0, \theta), \theta>0$ 的一组简单样本，$\theta$ 的先验密度为 $\pi(\theta)=$ $1 /\left(2 \theta^2\right), \theta \geq 1 / 2$ 。 考虑假设检验问题 $H_0: \theta \leq 1 \leftrightarrow H_1: \theta>1$ ，则其 Bayes 因子 $\mathrm{BF}_{01}$为 $\underline{\left[\left(x_{(n)} \vee 0.5\right)^{-n-1}-1\right] \vee 0}$ \\
解：样本联合密度与先验分别为
$$
f(\boldsymbol{x} \mid \theta)=\theta^{-n} \cdot \mathbb{I}_{\left\{0<x_{(n)}<\theta\right\}}, \quad \pi(\theta)=0.5 \theta^{-2} \cdot \mathbb{I}_{\{\theta \geq 0.5\}}
$$
因此 $\theta$ 的后验密度为
$$
\pi(\theta \mid \boldsymbol{x}) \propto \theta^{-n-2} \cdot \mathbb{I}_{\left\{\theta>x_{(n)} \vee 0.5\right\}}
$$
归一化后可得后验密度，进而求得后验分布函数为
$$
\Pi(\theta \mid \boldsymbol{x})= \begin{cases}1-\left(\frac{\theta_*}{\theta}\right)^{n+1}, & \theta \geq \theta_* \\ 0, & \theta<\theta_*\end{cases}
$$
其中 $\theta_*=x_{(n)} \vee 0.5$ ．于是当 $\theta_*<1$ ，即 $x_{(n)}<1$ 时，
$$
\alpha_0=\mathrm{P}(\theta \leq 1 \mid \boldsymbol{x})=\Pi(1 \mid \boldsymbol{x})=1-\theta_*^{n+1}, \quad \alpha_1=1-\alpha_0=\theta_*^{n+1}
$$
当 $\theta_* \geq 1$ ，即 $x_{(n)} \geq 1$ 时，$\alpha_0=0, \alpha_1=1$ ．又因为 $\pi_0=\mathrm{P}(\theta \leq 1)=0.5, \pi_1=\mathrm{P}(\theta>1)=0.5$ ，所以贝叶斯因子为
$$
\mathrm{BF}_{01}=\frac{\alpha_0 / \alpha_1}{\pi_0 / \pi_1}=\left\{\begin{array}{ll}
	\theta_*^{-n-1}-1, & \theta_*<1, \\
	0, & \theta_* \geq 1
\end{array}=\left[\left(x_{(n)} \vee 0.5\right)^{-n-1}-1\right] \vee 0\right.
$$\\



\noindent 二．（20 分）设从总体
$$
\begin{tabular}{c|ccc}
	$X$ & 0 & 1 & 2 \\
	\hline P & $p_1$ & $p_2$ & $p_3$
\end{tabular}
$$
（其中 $0<p_1, p_2, p_3<1, p_1+p_2+p_3=1$ 为末知参数）中抽取的一个简单样本 $X_1, \ldots, X_n$ ，试\\
（1）求 $p_1-p_2$ 的最大似然估计，并证明其为最小方差无偏估计。\\
（2）求检验问题 $H_0: p_1=p_2 \leftrightarrow H_1: p_1 \neq p_2$ 的一个（渐近）水平 $\alpha$ 检验。\\
解：（1）似然函数为
$$
L\left(p_1, p_2 ; \boldsymbol{x}\right)=p_1^{n_0} p_2^{n_1}\left(1-p_1-p_2\right)^{n-n_0-n_1}
$$
其中 $n_i=\sum_{j=1}^n \mathbb{I}_{\left\{X_j=i\right\}}, i=0,1$ ．由对数似然方程
$$
\left\{\begin{array}{l}
	\frac{\partial l\left(p_1, p_2 ; \boldsymbol{x}\right)}{\partial p_1}=\frac{n_0}{p_1}-\frac{n-n_0-n_1}{1-p_1-p_2}=0 \\
	\frac{\partial l\left(p_1, p_2 ; \boldsymbol{x}\right)}{\partial p_2}=\frac{n_1}{p_2}-\frac{n-n_0-n_1}{1-p_1-p_2}=0
\end{array}\right.
$$
解得 $p_1, p_2$ 的最大似然估计分别为
$$
\hat{p}_1=\frac{n_0}{n}, \quad \hat{p}_2=\frac{n_1}{n}
$$
进一步由最大似然估计的不变性可知 $p_1-p_2$ 的最大似然估计为 $\hat{p}_1-\hat{p}_2=\left(n_0-n_1\right) / n$ ．\\
最小方差无偏估计：将样本联合密度函数写成指数族形式如下
$$
f\left(\boldsymbol{x} ; p_1, p_2\right)=\exp \left\{n_0 \log \frac{p_1}{1-p_1-p_2}+n_1 \log \frac{p_2}{1-p_1-p_2}\right\} \cdot\left(1-p_1-p_2\right)^n
$$
令 
$$\eta_1=\log \frac{p_1}{1-p_1-p_2}, \eta_2=\log \frac{p_2}{1-p_1-p_2}$$
于是自然参数空间 
$$\Theta^*=\left\{\left(\eta_1, \eta_2\right):-\infty<\eta_1<\infty,-\infty<\eta_2<\infty\right\}$$
有内点，因此 $T=\left(n_0, n_1\right)$ 是 $\left(p_1, p_2\right)$ 的充分完全统计量．又注意到 $\hat{p}_1$ 和 $\hat{p}_2$ 分别是 $p_1$ 和 $p_2$ 的无偏估计，因此由 Lehmann-Scheffé 定理知 $p_1-p_2$ 的最大似然估计是最小方差无偏估计．\\
（2）法一：拟合优度检验，取检验统计量为
$$
K(\boldsymbol{X})=\sum_{r=1}^3 \frac{\left(n_{r-1}-n \hat{p}_r\right)^2}{n \hat{p}_r} \xrightarrow{H_0} \chi_{3-1-1}^2,
$$
其中 $\hat{p}_r$ 为 $H_0$ 下的极大似然估计．注意到当 $p_1=p_2=p$ 时，样本的似然函数为
$$
L(p ; \boldsymbol{x})=p^{n_0+n_1}(1-2 p)^{n_2} .
$$
由对数似然方程可得 $\hat{p}=\left(n_0+n_1\right) /(2 n)$ ．代入检验统计量表达式得
$$
K(\boldsymbol{X})=\frac{\left(n_0-n_1\right)^2}{n_0+n_1} .
$$
因此检验问题渐近水平 $\alpha$ 检验为
$$
\phi(\boldsymbol{X})= \begin{cases}1, & \text { 当 }\left(n_0-n_1\right)^2>\left(n_0+n_1\right) \chi_1^2(\alpha), \\ 0, & \text { 当 }\left(n_0-n_1\right)^2 \leq\left(n_0+n_1\right) \chi_1^2(\alpha) .\end{cases}
$$
法二：似然比检验，注意到似然比
$$
\lambda(\boldsymbol{X})=\frac{\sup _{\theta \in \Theta} L(\theta)}{\sup _{\theta \in \Theta_0} L(\theta)}=\frac{\hat{p}_1^{n_0} \hat{p}_2^{n_1}\left(1-\hat{p}_1-\hat{p}_2\right)^{n_2}}{\hat{p}^{\left(n_0+n_1\right)}(1-2 \hat{p})^{n_2}}
$$
在大样本下，我们有 $2 \log \lambda(\boldsymbol{X}) \xrightarrow{H_0} \chi_1^2$ ．代入检验统计量表达式得
$$
2 \log \lambda(\boldsymbol{X})=2 \log \frac{\left(n_0 / n\right)^{n_0} \cdot\left(n_1 / n\right)^{n_1}}{\left(n_0+n_1\right)^{n_0+n_1} /(2 n)^{n_0+n_1}}=2 n_0 \log \frac{2 n_0}{n_0+n_1}+2 n_1 \log \frac{2 n_1}{n_0+n_1}
$$
因此检验问题渐近水平 $\alpha$ 检验为
$$
\phi(\boldsymbol{X})= \begin{cases}1, & \text { 当 } 2 n_0 \log \frac{2 n_0}{n_0+n_1}+2 n_1 \log \frac{2 n_1}{n_0+n_1}>\chi_1^2(\alpha), \\ 0, & \text { 当 } 2 n_0 \log \frac{2 n_0}{n_0+n_1}+2 n_1 \log \frac{2 n_1}{n_0+n_1} \leq \chi_1^2(\alpha) .\end{cases}
$$
法三：利用渐近正态检验，注意到
$$
\hat{p}_1-\hat{p}_2=\frac{n_0-n_1}{n}=\frac{1}{n} \sum_{j=1}^n\left[\mathbb{I}_{\left\{X_j=0\right\}}-\mathbb{I}_{\left\{X_j=1\right\}}\right]
$$
是独立随机变量之平均，于是由中心极限定理知
$$
\frac{\sqrt{n}\left(\hat{p}_1-\hat{p}_2-\mathbb{E}\left[\mathbb{I}_{\left\{X_j=0\right\}}-\mathbb{I}_{\left\{X_j=1\right\}}\right]\right)}{\sqrt{\operatorname{Var}\left[\mathbb{I}_{\left\{X_j=0\right\}}-\mathbb{I}_{\left\{X_j=1\right\}}\right]}} \xrightarrow{D} N(0,1)
$$
其中 $$\mathbb{E}\left[\mathbb{I}_{\left\{X_1=0\right\}}-\mathbb{I}_{\left\{X_1=1\right\}}\right]=p_1-p_2\quad \operatorname{Var}\left[\mathbb{I}_{\left\{X_1=0\right\}}-\mathbb{I}_{\left\{X_1=1\right\}}\right]=p_1+p_2-\left(p_1-p_2\right)^2$$
结合 Slutsky 定理，因此考虑取检验统计量为
$$
U(\boldsymbol{X})=\frac{\sqrt{n}\left(\hat{p}_1-\hat{p}_2\right)}{\sqrt{\hat{p}_1+\hat{p}_2-\left(\hat{p}_1-\hat{p}_2\right)^2}}
$$
在 $H_0$ 下，我们有 $U(\boldsymbol{X}) \xrightarrow{D} N(0,1)$ ．于是检验问题渐近水平 $\alpha$ 检验为
$$
\phi(\boldsymbol{X})= \begin{cases}1, & \text { 当 }|U(\boldsymbol{X})|>u_{\alpha / 2}, \\ 0, & \text { 当 }|U(\boldsymbol{X})| \leq u_{\alpha / 2} .\end{cases}
$$
法四：利用 Wald 检验，记 $\boldsymbol{\theta}=\left(p_1, p_2\right)^{T}, \hat{\boldsymbol{\theta}}=\left(\hat{p}_1, \hat{p}_2\right)^{T}$ ，于是由中心极限定理有
$$
\sqrt{n}(\hat{\boldsymbol{\theta}}-\boldsymbol{\theta}) \xrightarrow{D} N\left(0, \boldsymbol{I}^{-1}(\boldsymbol{\theta})\right),
$$
其中总体（单个样本）的 Fisher 信息阵为
$$
\boldsymbol{I}(\theta)=\left(\begin{array}{cc}
	p_1^{-1}+p_3^{-1} & p_3^{-1} \\
	p_3^{-1} & p_2^{-1}+p_3^{-1}
\end{array}\right)
$$
注意 $h(\boldsymbol{\theta})=p_1-p_2, \boldsymbol{B}=\partial h / \partial \boldsymbol{\theta}=(1,-1)$ ，因此取检验统计量为
$$
W_n=n h(\hat{\boldsymbol{\theta}})\left[\boldsymbol{B}(\hat{\boldsymbol{\theta}}) \boldsymbol{I}^{-1}(\hat{\boldsymbol{\theta}}) \boldsymbol{B}^{T}(\hat{\boldsymbol{\theta}})\right]^{-1} h(\hat{\boldsymbol{\theta}})=\frac{n\left(\hat{p}_1-\hat{p}_2\right)^2}{\hat{p}_1+\hat{p}_2-\left(\hat{p}_1-\hat{p}_2\right)^2}
$$
在 $H_0$ 下，我们有 $W_n \xrightarrow{D} \chi_1^2$ ．于是检验问题渐近水平 $\alpha$ 检验为
$$
\phi(\boldsymbol{X})= \begin{cases}1, & \text { 当 } W_n>\chi_1^2(\alpha), \\ 0, & \text { 当 } W_n \leq \chi_1^2(\alpha) .\end{cases}
$$\\




\noindent 三．（30 分）设 $X_1, \ldots, X_n$ i.i.d.$\sim N(\mu, 1)$ ，其中 $\mu$ 为参数．对水平 $\alpha$ ，试\\
（1）求 $\mathrm{P}\left(X_1>0\right)$ 的最大似然估计，并求其渐近方差。\\
（2）证明检验问题 $H_0: \mu=\mu_0 \leftrightarrow H_1: \mu \neq \mu_0$ 不存在 UMPT，其中 $\mu_0$ 为一已知数．\\
（3）若参数 $\mu$ 在 $\mu=\mu_0$ 上的先验概率为 0.6 ，在 $\mu \neq \mu_0$ 上的先验分布为 $N\left(\mu_0, 4\right)$ ，损失函数取为 0-1 损失，求（2）中的假设检验问题的 Bayes 决策。\\
解：（1）似然函数
$$
L(\mu ; \boldsymbol{x})=(2 \pi)^{-\frac{n}{2}} \exp \left\{-\frac{1}{2} \sum_{i=1}^n\left(x_i-\mu\right)^2\right\}=(2 \pi)^{-\frac{n}{2}} \exp \left\{-\frac{1}{2} \sum_{i=1}^n\left(x_i-\overline{x}\right)^2-\frac{n(\mu-\overline{x})^2}{2}\right\}
$$
因此 $\mu$ 的最大似然估计为 $\hat{\mu}=\overline{X}$ 。\\
由最大似然估计的不变性可知，$p=\mathrm{P}\left(X_1>0\right)=\Phi(\mu)$ 的最大似然估计为 $\hat{p}=\Phi(\hat{\mu})=\Phi(\overline{X})$ 。\\
注意到 $\overline{X} \sim N(\mu, 1 / n)$ ，由 Delta 方法可知 $\hat{p}$ 的渐近方差为
$$
[\phi(\mu)]^2 \cdot \frac{1}{n}=\frac{\exp \left\{-\mu^2\right\}}{2 n \pi}
$$
（2）首先注意到正态分布族（方差已知，均值为未知参数）关于 $T=\overline{X}$ 是单调似然比族。因而对检验问题 $H_0: \mu=\mu_0 \leftrightarrow H_1^{\prime}: \mu>\mu_0$ ，存在 UMPT 形如
$$
\phi_1(\boldsymbol{x})= \begin{cases}1, & \text { 当 } \overline{x}>\mu_0+u_\alpha / \sqrt{n}, \\ 0, & \text { 其他. }\end{cases}
$$
对检验问题 $H_0: \mu=\mu_0 \leftrightarrow H_1^{\prime \prime}: \mu<\mu_0$ ，存在 UMPT 形如
$$
\phi_2(\boldsymbol{x})= \begin{cases}1, & \text { 当 } \overline{x}<\mu_0-u_\alpha / \sqrt{n}, \\ 0, & \text { 其他. }\end{cases}
$$
显然 $\phi_1$ 和 $\phi_2$ 都是检验问题 $H_0 \leftrightarrow H_1$ 的水平 $\alpha$ 检验。\\
假设检验问题 $H_0 \leftrightarrow H_1$ 的 UMPT 存在，令其为 $\phi_0$ 。对固定 $\mu_1>\mu_0$ 和 $\mu_2<\mu_0$ ，检验 $\phi_0$ 也是简单假设 $H_0: \mu=\mu_0 \leftrightarrow K_1: \mu=\mu_1$ 和 $H_0: \mu=\mu_0 \leftrightarrow K_2: \mu=\mu_2$ 的UMPT．因此由 Neyman-Pearson 引理可知 $\phi_0$ 有形式
$$
\begin{aligned}
	& \phi_0(\boldsymbol{x})= \begin{cases}1, & \text { 当 } f\left(\boldsymbol{x} ; \mu_1\right)>k_1 f\left(\boldsymbol{x} ; \mu_0\right), \\
		0, & \text { 当 } f\left(\boldsymbol{x} ; \mu_1\right) \leq k_1 f\left(\boldsymbol{x} ; \mu_0\right),\end{cases} \\
	& \phi_0(\boldsymbol{x})= \begin{cases}1, & \text { 当 } f\left(\boldsymbol{x} ; \mu_2\right)>k_2 f\left(\boldsymbol{x} ; \mu_0\right), \\
		0, & \text { 当 } f\left(\boldsymbol{x} ; \mu_2\right) \leq k_2 f\left(\boldsymbol{x} ; \mu_0\right) .\end{cases}
\end{aligned}
$$
法一：考虑 $\boldsymbol{x} \in\left\{\boldsymbol{x}: \phi_0(\boldsymbol{x})=1\right\}$ ，由单调似然比的性质可知
\begin{enumerate}[label=\textbf{\textbullet}]
	\item 如果 $T(\boldsymbol{y})>T(\boldsymbol{x})$，则由第一个检验形式知 $\phi_0(\boldsymbol{y})=1$。
	\item 如果 $T(\boldsymbol{y})<T(\boldsymbol{x})$，则由第二个检验形式知 $\phi_0(\boldsymbol{y})=1$。
\end{enumerate}
于是要么 $\phi_0(\boldsymbol{y})=1$ 对所有 $\boldsymbol{y}$ 成立，要么 $\phi_0(\boldsymbol{x}) \neq 1$ 对所有 $\boldsymbol{x}$ 成立．这时 $\phi_0$ 的功效比 $\phi_1$ 和 $\phi_2$ 在各自的检验问题 $H_0 \leftrightarrow K_1$ 和 $H_0 \leftrightarrow K_2$ 都要小，导出矛盾。\\
法二：由唯一性可知，在 $\mu_1>\mu_0$ 上， $\phi_0=\phi_1$ ，a.e.；在 $\mu_2<\mu_0$ 上，$\phi_0=\phi_2$ ，a.e.由 $\phi_1$ 和 $\phi_2$ 的形式知这不可能成立。\\
（3）由题意知两个假设的后验概率分别为
$$
\alpha_0=\mathrm{P}\left(\mu=\mu_0 \mid \boldsymbol{x}\right)=\frac{\pi_0 f\left(\boldsymbol{x} \mid \mu_0\right)}{m(\boldsymbol{x})}, \quad \alpha_1=\mathrm{P}\left(\mu \neq \mu_0 \mid \boldsymbol{x}\right)=\frac{\pi_1 m_1(\boldsymbol{x})}{m(\boldsymbol{x})},
$$
或者直接注意到简单假设对复杂假设的贝叶斯因子有形式
$$
\mathrm{BF}_{01}(\boldsymbol{x})=\frac{f\left(\boldsymbol{x} \mid \mu_0\right)}{m_1(\boldsymbol{x})}, \Longrightarrow \frac{\alpha_0}{\alpha_1}=\frac{\pi_0 f\left(\boldsymbol{x} \mid \mu_0\right)}{\pi_1 m_1(\boldsymbol{x})},
$$
其中 
$$m(\boldsymbol{x})=\pi_0 f\left(\boldsymbol{x} \mid \mu_0\right)+\pi_1 m_1(\boldsymbol{x}), m_1(\boldsymbol{x})=\int_{\mu \neq \mu_0} f(\boldsymbol{x} \mid \mu) \pi(\mu) \mathrm{d} \mu$$
下面计算 $m_1(\boldsymbol{x})$ 如下
$$
\begin{aligned}
	m_1(\boldsymbol{x}) & =\int_{\mu \neq \mu_0} f(\boldsymbol{x} \mid \mu) \pi(\mu) \mathrm{d} \mu \\
	& =\int_{\mu \neq \mu_0}(2 \pi)^{-\frac{n}{2}} \exp \left\{-\frac{1}{2} \sum_{i=1}^n\left(x_i-\overline{x}\right)^2-\frac{n(\mu-\overline{x})^2}{2}\right\} \cdot(8 \pi)^{-\frac{1}{2}} \exp \left\{-\frac{\left(\mu-\mu_0\right)^2}{8}\right\} \mathrm{d} \mu \\
	& =\frac{(2 \pi)^{-\frac{n+1}{2}}}{2} \exp \left\{-\frac{(n-1) s^2}{2}\right\} \int_{\mu \neq \mu_0} \exp \left\{-\frac{A \mu^2-2 B \mu+C}{2}\right\} \mathrm{d} \mu \\
	& =\frac{(2 \pi)^{-\frac{n+1}{2}}}{2} \exp \left\{-\frac{(n-1) s^2}{2}\right\} \cdot(2 \pi / A)^{\frac{1}{2}} \exp \left\{-\frac{1}{2}\left(C-\frac{B^2}{A}\right)\right\} \\
	& =\frac{(2 \pi)^{-\frac{n}{2}}}{\sqrt{4 n+1}} \exp \left\{-\frac{(n-1) s^2}{2}-\frac{n\left(\overline{x}-\mu_0\right)^2}{2(4 n+1)}\right\}
\end{aligned}
$$
其中 
$$A=n+\frac{1}{4}, B=n \overline{x}+\frac{\mu_0}{4}, C=n \overline{x}^2+\frac{\mu_0^2}{4}$$
因此
$$
\frac{\alpha_0}{\alpha_1}=\frac{0.6(2 \pi)^{-\frac{n}{2}} \exp \left\{-\frac{(n-1) s^2}{2}-\frac{n\left(\overline{x}-\mu_0\right)^2}{2}\right\}}{0.4 \frac{(2 \pi)^{-\frac{n}{2}}}{\sqrt{4 n+1}} \exp \left\{-\frac{(n-1) s^2}{2}-\frac{n\left(\overline{x}-\mu_0\right)^2}{2(4 n+1)}\right\}}=\frac{3 \sqrt{4 n+1}}{2} \exp \left\{-\frac{2 n^2\left(\overline{x}-\mu_0\right)^2}{4 n+1}\right\}
$$
在 0-1 损失下，该检验问题的贝叶斯决策为
$$
\delta(\boldsymbol{x})= \begin{cases}a_0, & \text { 当 }\left(\overline{x}-\mu_0\right)^2 \leq \frac{4 n+1}{2 n^2} \log \frac{3 \sqrt{4 n+1}}{2}, \\ a_1, & \text { 其他 },\end{cases}
$$
其中 $a_0$ 表示接受假设 $H_0, a_1$ 表示接受假设 $H_1$ ．\\




\noindent 四．（30 分）设 $X_1, \ldots, X_m$ i．i．d．$\sim \operatorname{Exp}\left(\lambda_1\right)$（期望是 $1 / \lambda_1$ 的指数分布），$Y_1, \ldots, Y_n$ i．i．d．$\sim \operatorname{Exp}\left(\lambda_2\right)$ ，且样本 $X_1, \ldots, X_m$ 和 $Y_1, \ldots, Y_n$ 独立，其中 $\lambda_1, \lambda_2$ 为正参数。记 $\overline{X}$ 和 $\overline{Y}$ 分别为两组样本的样本均值．试\\
（1）求 $\mathbb{E}\left[\left(X_1-Y_1\right)^2 \mid \overline{X}, \overline{Y}\right]$ 。\\
（2）求 $\lambda_1 / \lambda_2$ 的置信系数为 $1-\alpha$ 的置信区间．\\
（3）求检验问题 $H_0: \lambda_1=c \lambda_2 \leftrightarrow H_1: \lambda_1 \neq c \lambda_2$ 的水平 $\alpha$ 似然比检验。\\
解：（1）法一：由指数分布的性质知
$$
\mathbb{E}\left[\left(X_1-Y_1\right)^2\right]=\mathbb{E}\left(X_1^2\right)-2 \mathbb{E}\left(X_1 Y_1\right)+\mathbb{E}\left(Y_1^2\right)=\frac{2}{\lambda_1^2}-\frac{2}{\lambda_1 \lambda_2}+\frac{2}{\lambda_2^2} .
$$
注意到 $(\overline{X}, \overline{Y})$ 是 $\left(\lambda_1, \lambda_2\right)$ 的充分完全统计量，由 UMVUE 的唯一性可知
$$
\mathbb{E}\left[\left(X_1-Y_1\right)^2 \mid \overline{X}, \overline{Y}\right]=\left(\frac{2}{\lambda_1^2}-\frac{2}{\lambda_1 \lambda_2}+\frac{2}{\lambda_2^2}\right)_{\mathrm{UMVUE}}
$$
显然地，我们有
$$
\mathbb{E}\left(\overline{X}^2\right)=\operatorname{Var}(\overline{X})+[\mathbb{E}(\overline{X})]^2=\frac{m+1}{m \lambda_1^2}, \quad \mathbb{E}\left(\overline{Y}^2\right)=\operatorname{Var}(\overline{Y})+[\mathbb{E}(\overline{Y})]^2=\frac{n+1}{n \lambda_2^2} .
$$
因此
$$
\mathbb{E}\left[\left(X_1-Y_1\right)^2 \mid \overline{X}, \overline{Y}\right]=\frac{2 m \overline{X}^2}{m+1}-2 \overline{X} \overline{Y}+\frac{2 n \overline{Y}^2}{n+1} .
$$
法二：由条件期望的线性性及独立性可知
$$
\mathbb{E}\left[\left(X_1-Y_1\right)^2 \mid \overline{X}, \overline{Y}\right]=\mathbb{E}\left(X_1^2 \mid \overline{X}\right)-2 \mathbb{E}\left(X_1 Y_1 \mid \overline{X}, \overline{Y}\right)+\mathbb{E}\left(Y_1^2 \mid \overline{Y}\right) .
$$
注意到 
$$X_1 /(m \overline{X}) \sim \operatorname{Be}(1, m-1), Y_1 /(n \overline{Y}) \sim \operatorname{Be}(1, n-1)$$
且 $(\overline{X}, \overline{Y})$ 是 $\left(\lambda_1, \lambda_2\right)$ 的充分完全统计量，由 Basu 定理可知
$$
\begin{aligned}
	& \mathbb{E}\left(X_1^2 \mid \overline{X}\right)=\overline{X}^2 \cdot \mathbb{E}\left(\left.\frac{X_1^2}{\overline{X}^2} \right\rvert\, \overline{X}\right)=\overline{X}^2 \cdot \mathbb{E}\left(\frac{X_1^2}{\overline{X}^2}\right), \quad \mathbb{E}\left(Y_1^2 \mid \overline{Y}\right)=\overline{Y}^2 \cdot \mathbb{E}\left(\frac{Y_1^2}{\overline{Y}^2}\right), \\
	& \mathbb{E}\left(X_1 Y_1 \mid \overline{X}, \overline{Y}\right)=\overline{X} \overline{Y} \mathbb{E}\left(\left.\frac{X_1}{\overline{X}} \cdot \frac{Y_1}{\overline{Y}} \right\rvert\, \overline{X}, \overline{Y}\right)=\overline{X} \overline{Y} \mathbb{E}\left(\frac{X_1}{\overline{X}}\right) \cdot \mathbb{E}\left(\frac{Y_1}{\overline{Y}}\right) .
\end{aligned}
$$
由贝塔分布性质知
$$
\mathbb{E}\left(\frac{X_1}{m \overline{X}}\right)=\frac{1}{m}, \quad \mathbb{E}\left(\frac{X_1^2}{m^2 \overline{X}^2}\right)=\frac{2}{m(m+1)}, \quad \mathbb{E}\left(\frac{Y_1}{n \overline{Y}}\right)=\frac{1}{n}, \quad \mathbb{E}\left(\frac{Y_1^2}{n^2 \overline{Y}^2}\right)=\frac{2}{n(n+1)} .
$$
于是代入可得
$$
\mathbb{E}\left[\left(X_1-Y_1\right)^2 \mid \overline{X}, \overline{Y}\right]=\frac{2 m \overline{X}^2}{m+1}-2 \overline{X} \overline{Y}+\frac{2 n \overline{Y}^2}{n+1}
$$
（2）注意 $2 m \lambda_1 \overline{X} \sim \chi_{2 m}^2, 2 n \lambda_2 \overline{Y} \sim \chi_{2 n}^2$ ，取枢轴变量为
$$
\frac{\lambda_1 \overline{X}}{\lambda_2 \overline{Y}} \sim F_{2 m, 2 n}
$$
由 $\mathrm{P}\left(F_{2 m, 2 n}(1-\alpha / 2) \leq \frac{\lambda_1 \overline{X}}{\lambda_2 \overline{Y}} \leq F_{2 m, 2 n}(\alpha / 2)\right)=1-\alpha$ ，反解得到 $\lambda_1 / \lambda_2$ 的置信系数为 $1-\alpha$ 的置信区间为
$$
\left[F_{2 m, 2 n}(1-\alpha / 2) \cdot \frac{\overline{Y}}{\overline{X}}, F_{2 m, 2 n}(\alpha / 2) \cdot \frac{\overline{Y}}{\overline{X}}\right] .
$$
（3）似然函数
$$
L\left(\lambda_1, \lambda_2 ; \boldsymbol{x}, \boldsymbol{y}\right)=\lambda_1^m \exp \left\{-\lambda_1 \sum_{i=1}^m x_i\right\} \cdot \lambda_2^n \exp \left\{-\lambda_2 \sum_{j=1}^n y_j\right\} .
$$
由似然比检验的思想，取检验统计量为
\[
\Lambda(\boldsymbol{x}, \boldsymbol{y})=\frac{\sup _{\lambda_1>0, \lambda_2>0} L\left(\lambda_1, \lambda_2 ; \boldsymbol{x}, \boldsymbol{y}\right)}{\sup _{\lambda_1 / \lambda_2=c} L\left(\lambda_1, \lambda_2 ; \boldsymbol{x}, \boldsymbol{y}\right)} .
\]
注意到全空间下 $\hat{\lambda}_1=1 / \overline{X}, \hat{\lambda}_2=1 / \overline{Y}$ ．在原假设空间下，记 $\lambda_1=c \lambda, \lambda_2=\lambda$ ，考虑 $\lambda$ 的似然函数为
$$
L(\lambda ; \boldsymbol{x}, \boldsymbol{y})=c^m \lambda^{m+n} \exp \{-\lambda(c m \overline{x}+n \overline{y})\}
$$
此时最大似然估计 $\hat{\lambda}=(m+n) /(c m \overline{x}+n \overline{y})$ ．于是似然比可化简为
$$
\begin{aligned}
	\Lambda(\boldsymbol{x}, \boldsymbol{y})=\frac{L\left(\hat{\lambda}_1, \hat{\lambda}_2 ; \boldsymbol{x}, \boldsymbol{y}\right)}{L(c \hat{\lambda}, \hat{\lambda} ; \boldsymbol{x}, \boldsymbol{y})} & =\frac{(c m \overline{x}+n \overline{y})^{m+n}}{c^m(m+n)^{m+n} \overline{x}^m \cdot \overline{y}^n} \\
	& =\frac{1}{(m+n)^{m+n}}\left(m+n \frac{\overline{y}}{c \overline{x}}\right)^m\left(n+m \frac{c \overline{x}}{\overline{y}}\right)^n \\
	& \triangleq \frac{1}{(m+n)^{m+n}}\left(m+n F^{-1}\right)^m(n+m F)^n
\end{aligned}
$$
其中 $F:=F(\boldsymbol{x}, \boldsymbol{y})=c \overline{x} / \overline{y}$ ．注意到 $\Lambda$ 关于 $F$ 先递减后递增，因此检验的拒绝域的形式为
$$
R=\left\{(\boldsymbol{X}, \boldsymbol{Y}): F(\boldsymbol{X}, \boldsymbol{Y})<c_1 \text { 或 } F(\boldsymbol{X}, \boldsymbol{Y})>c_2\right\} \text {. }
$$
注意到 $2 m \lambda_1 \overline{X} \sim \chi_{2 m}^2, 2 n \lambda_2 \overline{Y} \sim \chi_{2 n}^2$ ，所以在 $H_0$ 下，
$$
F(\boldsymbol{X}, \boldsymbol{Y})=\frac{c \overline{X}}{\overline{Y}} \sim F_{2 m, 2 n}
$$
由显著性水平 $\alpha$ 要求知 $c_1=F_{2 m, 2 n}(1-\alpha / 2), c_2=F_{2 m, 2 n}(\alpha / 2)$ ．	
	
	
	
	
\end{document}